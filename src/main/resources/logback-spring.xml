<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE configuration>
<configuration debug="false" scan="true" scanPeriod="15 second">
    <springProperty scope="context" name="application.name" source="spring.application.name"
                    defaultValue="elk-demo"/>
    <springProperty scope="context" name="logback.queue.size" source="logback.queue.size" defaultValue="8192"/>
    <!-- file info -->
    <springProperty scope="context" name="file.size" source="logback.file.size" defaultValue="300MB"/>
    <springProperty scope="context" name="file.max.history" source="logback.file.max.history" defaultValue="30"/>
    <springProperty scope="context" name="file.total.size.cap" source="logback.file.total.size.cap"
                    defaultValue="2048MB"/>

    <property name="file.path" value="logs/${application.name}/"/>
    <property name="file.name" value="${application.name}"/>

    <!-- Date format -->
    <property name="date_format" value="yyyy-MM-dd HH:mm:ss.SSS"/>

    <!-- This is the ConsoleAppender -->
    <appender name="consoleAppender" class="ch.qos.logback.core.ConsoleAppender">
        <encoder charset="utf-8">
            <pattern>[%-5level] %d{${date_format}} [%thread] [%logger{36}#%M:%L] - %m%n</pattern>
        </encoder>
    </appender>


    <!-- 输入到文件，按日期和文件大小 -->
    <appender name="fileAppender" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <encoder charset="utf-8">
            <pattern>[%-5level] %d{${date_format}} [%thread] [%X{traceId}] [%logger{36}#%M:%L] - %m%n</pattern>
        </encoder>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>${file.path}%d/${file.name}.%i.log</fileNamePattern>
            <maxHistory>${file.max.history}</maxHistory>
            <timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP">
                <maxFileSize>${file.size}</maxFileSize>
            </timeBasedFileNamingAndTriggeringPolicy>
            <totalSizeCap>${file.total.size.cap}</totalSizeCap>
        </rollingPolicy>
    </appender>

    <!--输出到kafka-->
    <appender name="kafkaAppender" class="com.github.danielwegener.logback.kafka.KafkaAppender">
        <encoder>
            <pattern>
                {
                "service":"elk-demo",
                "date":"%d{yyyy-MM-dd HH:mm:ss}",
                "level":"%level",
                "thread": "%thread",
                "logger": "%logger{36}",
                "msg":"%msg"
                }
            </pattern>
        </encoder>
        <topic>elktopic</topic>
        <keyingStrategy class="com.github.danielwegener.logback.kafka.keying.NoKeyKeyingStrategy"/>
        <deliveryStrategy class="com.github.danielwegener.logback.kafka.delivery.AsynchronousDeliveryStrategy"/>
        <producerConfig>bootstrap.servers=192.168.48.120:9092</producerConfig>
        <!-- don't wait for a broker to ack the reception of a batch.  -->
        <producerConfig>acks=0</producerConfig>
    </appender>

<!--    <appender name="asyncFileAppender" class="ch.qos.logback.classic.AsyncAppender">-->
<!--        <queueSize>${logback.queue.size}</queueSize>-->
<!--        <neverBlock>true</neverBlock>-->
<!--        <appender-ref ref="fileAppender"/>-->
<!--        <appender-ref ref="kafkaAppender"/>-->
<!--    </appender>-->

    <!--
        Log level is divided from low to high: TRACE < DEBUG < INFO < WARN < ERROR < FATAL
        If set to WARN, information below WARN will not be output.
    -->
    <root level="INFO">
        <appender-ref ref="consoleAppender"/>
        <appender-ref ref="kafkaAppender"/>
    </root>
</configuration>
